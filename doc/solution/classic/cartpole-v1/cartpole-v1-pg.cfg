{'_fake_gpus': False,
 'action_space': None,
 'actions_in_input_normalized': False,
 'batch_mode': 'complete_episodes',
 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>,
 'clip_actions': False,
 'clip_rewards': None,
 'collect_metrics_timeout': 180,
 'compress_observations': False,
 'create_env_on_driver': False,
 'custom_eval_function': None,
 'custom_resources_per_worker': {},
 'eager_tracing': False,
 'env': 'CartPole-v1',
 'env_config': {},
 'env_task_fn': None,
 'evaluation_config': {'explore': False,
                       'record_env': '/media/hdd-stuff/home/bob/Stuff/python/rllib-exercises/tmp/run/CartPole-v1/video',
                       'render_env': True},
 'evaluation_interval': 9999999999,
 'evaluation_num_episodes': 2,
 'evaluation_num_workers': 1,
 'evaluation_parallel_to_training': False,
 'exploration_config': {'type': 'StochasticSampling'},
 'explore': True,
 'extra_python_environs_for_driver': {},
 'extra_python_environs_for_worker': {},
 'fake_sampler': False,
 'framework': 'tf',
 'gamma': 0.99,
 'horizon': None,
 'ignore_worker_failures': False,
 'in_evaluation': False,
 'input': 'sampler',
 'input_config': {},
 'input_evaluation': ['is', 'wis'],
 'local_tf_session_args': {'inter_op_parallelism_threads': 8,
                           'intra_op_parallelism_threads': 8},
 'log_level': 'WARN',
 'log_sys_usage': True,
 'logger_config': None,
 'lr': 0.0006,
 'metrics_smoothing_episodes': 100,
 'min_iter_time_s': 0,
 'model': {'fcnet_hiddens': [64, 32]},
 'monitor': -1,
 'multiagent': {'count_steps_by': 'env_steps',
                'observation_fn': None,
                'policies': {},
                'policies_to_train': None,
                'policy_map_cache': None,
                'policy_map_capacity': 100,
                'policy_mapping_fn': None,
                'replay_mode': 'independent'},
 'no_done_at_end': False,
 'normalize_actions': True,
 'num_cpus_for_driver': 1,
 'num_cpus_per_worker': 0,
 'num_envs_per_worker': 1,
 'num_gpus': 0,
 'num_gpus_per_worker': 0,
 'num_workers': 1,
 'observation_filter': 'NoFilter',
 'observation_space': None,
 'optimizer': {},
 'output': None,
 'output_compress_columns': ['obs', 'new_obs'],
 'output_max_file_size': 67108864,
 'placement_strategy': 'PACK',
 'postprocess_inputs': False,
 'preprocessor_pref': 'deepmind',
 'record_env': False,
 'remote_env_batch_wait_ms': 0,
 'remote_worker_envs': False,
 'render_env': False,
 'rollout_fragment_length': 200,
 'sample_async': False,
 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,
 'seed': 3010392425,
 'shuffle_buffer_size': 0,
 'simple_optimizer': -1,
 'soft_horizon': False,
 'synchronize_filters': True,
 'tf_session_args': {'allow_soft_placement': True,
                     'device_count': {'CPU': 1},
                     'gpu_options': {'allow_growth': True},
                     'inter_op_parallelism_threads': 2,
                     'intra_op_parallelism_threads': 2,
                     'log_device_placement': False},
 'timesteps_per_iteration': 0,
 'train_batch_size': 200}
